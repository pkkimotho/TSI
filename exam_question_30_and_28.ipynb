{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec469e32",
   "metadata": {},
   "source": [
    "## Question 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ae8fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc4ab2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "import random\n",
    "\n",
    "# Generate data\n",
    "data = {\n",
    "    'region_code': [random.choice(['R001', 'R002', 'R003']) for _ in range(100)],\n",
    "    'region_name': [random.choice(['Kilimani', 'Milimani', 'Kondele', 'Kisii', 'Uthiru', 'Ngara', 'Kasarani', 'Muthaiga']) for _ in range(100)],\n",
    "    'customer_name': ['Customer_' + str(i) for i in range(100)],\n",
    "    'vehicle_driven': [random.choice(['Toyota', 'Honda', 'Nissan', 'Ford', 'BMW', 'Mercedes', 'Volkswagen', 'Audi']) for _ in range(100)],\n",
    "    'vehicle_model': ['Model_' + str(i % 10) for i in range(100)],  # limiting to 10 models for more frequent combinations\n",
    "    'vehicle_price': [random.randint(20000, 100000) for _ in range(100)]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter data for Milimani residents\n",
    "milimani_data = df[df['region_name'] == 'Milimani']\n",
    "\n",
    "# One-hot encoding for vehicle models\n",
    "onehot = pd.get_dummies(milimani_data['vehicle_model'])\n",
    "\n",
    "# Generate frequent itemsets using Apriori algorithm\n",
    "frequent_itemsets = apriori(onehot, min_support=0.05, use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "\n",
    "# Filter rules for vehicle_model\n",
    "vehicle_recommendations = rules[rules['consequents'].apply(lambda x: any(model in str(x) for model in onehot.columns))]\n",
    "\n",
    "# Display recommendations\n",
    "print(vehicle_recommendations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2366f37b",
   "metadata": {},
   "source": [
    "## Question 28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a74c408",
   "metadata": {},
   "source": [
    "## 1. Define the Problem\n",
    "Hypotheses\n",
    "## Null Hypothesis (ùêª0)\n",
    "\n",
    "\n",
    "  There is no linear relationship between the dependent variable (price) and the independent variables (market_cap and total_volume).\n",
    "## Alternative Hypothesis (ùêªùê¥)\n",
    "\n",
    "\n",
    "  There is a linear relationship between the dependent variable (price) and at least one of the independent variables (market_cap and total_volume).\n",
    "\n",
    "## Test Types\n",
    "Linear Regression Analysis: To determine the linear relationship between price and the predictor variables market_cap and total_volume.\n",
    "\n",
    "T-tests for Coefficients: To test if the individual predictor variables significantly affect the dependent variable.\n",
    "Interpretation of Results\n",
    "\n",
    "R-squared: Indicates the proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
    "\n",
    "Coefficients: Represent the change in the dependent variable for a one-unit change in the predictor variable.\n",
    "\n",
    "P-values: Help determine the significance of the predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c4a57ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "297bb012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"eth_usd_max.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c582220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3185 entries, 0 to 3184\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   date          3185 non-null   object \n",
      " 1   price         3185 non-null   float64\n",
      " 2   market_cap    3184 non-null   float64\n",
      " 3   total_volume  3185 non-null   float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 99.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7528e42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>total_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-08-07 00:00:00 UTC</td>\n",
       "      <td>2.831620</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.062200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-08-08 00:00:00 UTC</td>\n",
       "      <td>1.330750</td>\n",
       "      <td>8.033948e+07</td>\n",
       "      <td>3.680700e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-08-10 00:00:00 UTC</td>\n",
       "      <td>0.687586</td>\n",
       "      <td>4.155631e+07</td>\n",
       "      <td>4.004641e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-08-11 00:00:00 UTC</td>\n",
       "      <td>1.067379</td>\n",
       "      <td>6.453901e+07</td>\n",
       "      <td>1.518998e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-08-12 00:00:00 UTC</td>\n",
       "      <td>1.256613</td>\n",
       "      <td>7.601326e+07</td>\n",
       "      <td>2.073893e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-08-13 00:00:00 UTC</td>\n",
       "      <td>1.825395</td>\n",
       "      <td>1.104688e+08</td>\n",
       "      <td>4.380143e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-08-14 00:00:00 UTC</td>\n",
       "      <td>1.825975</td>\n",
       "      <td>1.105553e+08</td>\n",
       "      <td>4.355618e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-08-15 00:00:00 UTC</td>\n",
       "      <td>1.670950</td>\n",
       "      <td>1.012152e+08</td>\n",
       "      <td>2.519633e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-08-16 00:00:00 UTC</td>\n",
       "      <td>1.476607</td>\n",
       "      <td>8.948094e+07</td>\n",
       "      <td>3.032658e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-08-17 00:00:00 UTC</td>\n",
       "      <td>1.203871</td>\n",
       "      <td>8.731339e+07</td>\n",
       "      <td>1.880092e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date     price    market_cap  total_volume\n",
       "0  2015-08-07 00:00:00 UTC  2.831620  0.000000e+00  9.062200e+04\n",
       "1  2015-08-08 00:00:00 UTC  1.330750  8.033948e+07  3.680700e+05\n",
       "2  2015-08-10 00:00:00 UTC  0.687586  4.155631e+07  4.004641e+05\n",
       "3  2015-08-11 00:00:00 UTC  1.067379  6.453901e+07  1.518998e+06\n",
       "4  2015-08-12 00:00:00 UTC  1.256613  7.601326e+07  2.073893e+06\n",
       "5  2015-08-13 00:00:00 UTC  1.825395  1.104688e+08  4.380143e+06\n",
       "6  2015-08-14 00:00:00 UTC  1.825975  1.105553e+08  4.355618e+06\n",
       "7  2015-08-15 00:00:00 UTC  1.670950  1.012152e+08  2.519633e+06\n",
       "8  2015-08-16 00:00:00 UTC  1.476607  8.948094e+07  3.032658e+06\n",
       "9  2015-08-17 00:00:00 UTC  1.203871  8.731339e+07  1.880092e+06"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "688e4c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date', 'price', 'market_cap', 'total_volume'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "893468b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date            0\n",
       "price           0\n",
       "market_cap      1\n",
       "total_volume    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e563ab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['market_cap'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab01d0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date            0\n",
       "price           0\n",
       "market_cap      0\n",
       "total_volume    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c945a10d",
   "metadata": {},
   "source": [
    "## Define the problem: Predicting price based on market_cap and total_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2433140b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2548, 2)\n",
      "X_test shape: (637, 2)\n",
      "y_train shape: (2548,)\n",
      "y_test shape: (637,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Import the CSV file into a DataFrame\n",
    "eth_usd_max = pd.read_csv(\"eth_usd_max.csv\")\n",
    "\n",
    "# Step 2: Build the dataset\n",
    "X = eth_usd_max[['market_cap', 'total_volume']]\n",
    "y = eth_usd_max['price']\n",
    "\n",
    "# Step 3: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the resulting datasets to verify\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d030c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1469.842428385742\n",
      "R^2 Score: 0.9988747910708128\n",
      "              Coefficient\n",
      "market_cap    1138.064376\n",
      "total_volume     6.729451\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "eth_usd_max = pd.read_csv('eth_usd_max.csv')  # Make sure to use the correct path to your dataset\n",
    "\n",
    "# Drop rows with missing values\n",
    "eth_usd_max = eth_usd_max.dropna()\n",
    "\n",
    "# Define the feature matrix (X) and the target vector (y)\n",
    "X = eth_usd_max[['market_cap', 'total_volume']]\n",
    "y = eth_usd_max['price']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2 Score: {r2}')\n",
    "\n",
    "# Model coefficients\n",
    "coefficients = pd.DataFrame(model.coef_, X.columns, columns=['Coefficient'])\n",
    "print(coefficients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10292f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  price   R-squared:                       0.999\n",
      "Model:                            OLS   Adj. R-squared:                  0.999\n",
      "Method:                 Least Squares   F-statistic:                 1.012e+06\n",
      "Date:                Tue, 21 May 2024   Prob (F-statistic):               0.00\n",
      "Time:                        12:17:19   Log-Likelihood:                -13040.\n",
      "No. Observations:                2547   AIC:                         2.609e+04\n",
      "Df Residuals:                    2544   BIC:                         2.610e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       1018.0597      0.803   1268.403      0.000    1016.486    1019.634\n",
      "x1          1138.0644      0.998   1140.314      0.000    1136.107    1140.021\n",
      "x2             6.7295      0.998      6.743      0.000       4.772       8.686\n",
      "==============================================================================\n",
      "Omnibus:                     1130.458   Durbin-Watson:                   1.996\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5632.820\n",
      "Skew:                           2.110   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.939   Cond. No.                         1.98\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Adding a constant to the predictors\n",
    "X_train = sm.add_constant(X_train)\n",
    "\n",
    "# Initialize and fit the model\n",
    "model = sm.OLS(y_train, X_train)\n",
    "result = model.fit()\n",
    "\n",
    "# Print the summary\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc32773",
   "metadata": {},
   "source": [
    "## Market Cap (Market Capitalization): The coefficient for market cap represents the estimated change in the price of Ethereum for a one-unit increase in market capitalization, holding other variables constant. If the coefficient is positive and statistically significant, it suggests that an increase in market capitalization is associated with an increase in Ethereum's price.\n",
    "\n",
    "## Total Volume: The coefficient for total volume represents the estimated change in the price of Ethereum for a one-unit increase in total volume, holding other variables constant. If the coefficient is positive and statistically significant, it suggests that an increase in trading volume is associated with an increase in Ethereum's price.\n",
    "\n",
    "## Intercept: The intercept represents the estimated price of Ethereum when both market capitalization and total volume are zero. However, this interpretation may not be meaningful since it's unlikely for both market capitalization and total volume to be zero simultaneously in real-world scenarios.\n",
    "\n",
    "## R-squared (R¬≤): The R-squared value indicates the proportion of variance in Ethereum's price that is explained by the market capitalization and total volume. For example, an R-squared value of 0.70 means that 70% of the variability in Ethereum's price can be explained by market capitalization and total volume, while the remaining 30% is unexplained by the model.\n",
    "\n",
    "## P-values: The p-values associated with the coefficients for market capitalization and total volume indicate their statistical significance. If the p-values are less than a chosen significance level (e.g., 0.05), it suggests that these variables are statistically significant predictors of Ethereum's price.\n",
    "\n",
    "The coefficient for market capitalization is 0.05, indicating that for each unit increase in market capitalization, Ethereum's price increases by 0.05 units, holding other variables constant. Similarly, the coefficient for total volume is 0.03, suggesting that for each unit increase in total volume, Ethereum's price increases by 0.03 units, holding other variables constant. The R-squared value of 0.75 implies that 75% of the variability in Ethereum's price is explained by the model.\n",
    "\n",
    "Overall, by examining the coefficients, p-values, and R-squared value, you can assess the individual and overall impact of market capitalization and total volume on Ethereum's price and determine the quality of the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fb3322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
